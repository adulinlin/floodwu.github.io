# 《深入理解计算机系统》读书笔记

## 第1章 计算机系统漫游
执行gcc -o hello hello.c，完成从C语言代码到可执行文件的整个过程分为以下4个阶段：
hello.c源程序（文本）  
    ->  预处理器（cpp）  ->  hello.i被修改的源程序（文本）
    ->  编译器（ccl）    ->  hello.s汇编程序（文本）
    ->  `汇编器`（as）   ->  hello.o可重定位目标程序（二进制）
    ->  链接器（ld）     ->  hello可执行目标程序（二进制）

（基础内容，略）

## 第2章 信息的表示和处理
计算机使用字节（8位的块）作为最小的可寻址的存储单位，而不是在存储器中访问单独的位。存储器的每个字节都由一个唯一的数字来标识，称为它的地址。

对于跨越多字节的程序对象必须建立两个规则：这个对象的地址是什么，以及在存储器中如何排列这些字节。最低有效字节在最前面的方式称为小端法，最高有效字节在最前面的方式称为大端法。假设变量x的类型为int，位于地址0x100处，它的16进制值为0x01234567，地址范围为0x100~0x103字节，其排列顺序可能如下：
0x100  0x101  0x102  0x103
  01     23     45     67        大端法
  67     45     23     01        小端法
在不同类型的机器之间传送数据时，字节的顺序会称为问题。

（二进制编码表示及运算，比较基础，略）


## 第3章 程序的机器级表示
gcc编译器以汇编代码形式产生输出，汇编代码是机器代码的文本表示，给出了程序中的每一条指令。然后gcc调用汇编器和链接器，根据汇编代码生成可执行的机器代码。
Linux使用了平坦寻址方式，因此可以将整个存储空间（包括栈、堆等）看做一个大的字节数组。

### 程序编码
执行：
gcc -O1 -o p p1.c p2.c
其中-O1指使用第一级优化。gcc会调用一系列程序来将源代码转化为可执行代码：
首先C预处理器扩展源代码，插入所有用#include指定的文件，并扩展所有用#define定义的宏；
然后编译器产生两个源代码的汇编代码:p1.s和p2.s；
接着汇编器将汇编代码转化为二进制目标代码：p1.o和p2.o，目标代码是机器代码的一种形式，它包含所有指令的二进制表示，但是还没有填入地址的全局值；
最后，链接器将两个目标代码文件与实现库函数的代码合并，并产生最终的可执行文件p。

对于机器级编程来说，有两种抽象尤为重要：
第一种是机器级程序的格式和行为，定义为指令集体系结构（Instruction set architecture），它定义了处理器状态、指令的格式，以及每条指令对状态的影响。大多数ISA把程序的行为描述成好像每条指令是按顺序执行的，实际处理器硬件远比描述的精细复杂，它们并发地执行许多指令，但是可以采取措施保证整体行为与ISA指定的顺序执行完全一致。
第二种是机器级程序使用的存储器地址是虚拟地址，提供的存储器模型看上去是一个非常大的字节数组，存储器系统的实际实现是将多个硬件存储器和操作系统软件组合起来。

编译器会将C语言提供的相对比较抽象的执行模型表示的程序转化为处理器执行的非常基本的指令，即汇编代码。汇编代码的表示非常接近于机器代码，如下C语言代码：
int accum = 0 ;
int sum(int x, int y){
	int t = x + y;
	accum += t;
	return t;
}
执行`gcc -O1 -S code.c`将产生一个如下内容的code.s文件：
sum:
  pushl %ebp
  movl  %esp,%ebp
  movl  12(%ebp),%eax
  addl  8(%ebp),%eax
  addl  %eax,accum
  popl  %ebp
  ret
这段代码中已经去除了所有关于局部变量名或数据类型的信息，且代码中有一个对全局变量accum的引用，这是因为编译器还不能确定这个变量会放在存储器中的哪个位置。
如果使用gcc -O1 -c code.c，将生产一个目标文件code.o，它是一个二进制文件，在文件中可以找到一段字节序列：
55 89 e5 8b 45 0c 03 45 08 01 05 00 00 00 00 5d c3
这段字节序列就是上面汇编代码对应的目标代码，`由此可见机器实际执行的程序只是对一系列指令进行编码的字节序列`。
在Linux上可以使用反汇编器objdump来生成目标代码对应的字节序列：
objdump -d code.o
生成结果如下：
00000000 <sum>:
 0:55                     pushl %ebp
 1:89 e5                  movl  %esp,%ebp
 3:8b 45 0c               movl  12(%ebp),%eax
 6:03 45 08               addl  8(%ebp),%eax
 9:01 05 00 00 00 00      addl  %eax,accum
 f:5d                     popl  %ebp
10:c3                     ret

生成实际可执行的代码需要对一组目标代码文件运行链接器，这一组目标代码文件中必须含有一个main函数。链接器将代码的地址移到一段地址范围中，且会确定全局变量的地址：
08048394 <sum>:
 8048394:55                     pushl %ebp
 8048395:89 e5                  movl  %esp,%ebp
 8048397:8b 45 0c               movl  12(%ebp),%eax
 804839a:03 45 08               addl  8(%ebp),%eax
 804839d:01 05 00 00 00 00      addl  %eax,0x804a018
 80483a3:5d                     popl  %ebp
 80483a4:c3                     ret
最终链接后生成的文件会比较大，是因为它不仅包含了多个文件的代码，还包含了用来启动和终止程序的信息，以及用来与操作系统交互的信息。

### 访问信息
IA32 CPU包含一组8个存储32位值的寄存器，这些寄存器用来存储整数数据和指针。大多数指令有一个或多个操作数用于指出执行一个操作中要引用的源数据值，以及放置结果的目标位置。源数据值可以以常数形式（如$12）给出，或者是从寄存器（如%eax）、存储器（如0x804a018）中读出。结果可以存放在寄存器或者存储器中。

### 算术和逻辑操作
（算术和逻辑运算指令的介绍，略）

### 控制
C语言中的某些结构，比如条件语句、循环语句、分支语句，要求有条件地执行。机器代码提供两种基本的低级机制来实现有条件的行为。除了整数寄存器，CPU还维护着一组单个位的`条件码寄存器`用于描述最近的算术或逻辑操作的结果。可以检测这些寄存器来执行条件分支指令。常用的条件码有：
CF:进位标志，最近的操作使最高位产生了进位，可以用来检查无符号操作数的溢出；
ZF:零标志，最近的操作得出的结果为0；
SF:符号标志，最近的操作得到的结果为负数；
OF:溢出标志，最近的操作导致一个补码溢出（正溢出或负溢出）

跳转指令会导致执行切换到程序中一个全新的位置，在汇编代码中，跳转的目的地通常用一个label表示。
如：
int absdiff(int x, int y){
	if(x < y){
		return y - x;
	}
	else{
		return x - y;
	}
} 
以上C语言代码将被编译为如下汇编代码：x在%ebp+8中，y在%ebp+12中
  movl 8(%ebp),%edx          获取x
  movl 12(%ebp),%eax         获取y
  cmpl %eax,%edx             比较x和y
  jge  .L2                   如果>=，则跳转.L2
  subl %edx,%eax             计算y-x
  jmp  .L3                   无条件跳转.L3
.L2:
  subl  %eax,%edx            计算x-y
  movl  %edx,%eax            两种情况下返回值都放在%eax中
.L3:                         结束

C语言中提供了多种循环结构，do-while、while、for等。可以使用条件测试和跳转组合起来实现循环的效果。大多数汇编器会根据一个循环的do-while形式来产生循环代码，其他的循环会首先转换成do-while形式，再编译成机器代码。

### 条件传送指令
实现条件操作的传统方法是利用控制的条件转移，当条件满足时程序沿着一条执行路径进行，而当条件不满足时，就走另一条路径。这种机制比较简单，但在现代处理器上可能会非常低效。条件转移是一种替代策略：先计算一个条件操作的两种结果，然后再根据条件是否满足从而选取一个，只有在一些受限的情况下这种策略才可行，但是如果可行，就可以用一条简单的条件传送指令来实现它。`条件传送指令更好地匹配了现代处理器的性能特性`。

使用条件表达式实现absdiff函数：
int absdiff(int x,int y){
	return x < y ? y-x :x-y;
}
生成的汇编代码如下：
  movl 8(%ebp),%ecx          获取x
  movl 12(%ebp),%edx         获取y
  movl %edx,%ebx             复制y
  subl %ecx,%ebx             计算y-x
  movl %ecx,%eax             复制x
  subl %edx,%eax             计算x-y，并设置为返回值
  cmpl %edx,%ecx             比较x，y
  cmovl %ebx,%eax            如果<，则将返回值替换为y-x    !!! 仅需一条指令图（条件传送指令）
以上汇编代码类似于如下的C语言代码：
  int tval = y-x;
  int rval = x-y;
  int test = x<y;

  // 只需一条指令
  if(test) {
    rval = tval;
  }

  return rval;
基于条件数据传送的代码比基于条件控制转移的代码性能好，原因在于：现代处理器使用流水线方式来执行指令，这种方式通过重叠连续指令的步骤来获得高性能，例如正在取一条指令的时候执行它前面一条指令的算术运算。要做到这一点，要求能够事先确定要执行指令的序列，这样才能够保持流水线中充满了待执行的指令。当机器遇到条件跳转时，它常常还不能确定是否会进行跳转，处理器使用非常精密的分支预测逻辑来猜测每条跳转指令是否会执行，如果它的猜测比较可靠，指令流水线中就会充满着指令，但是如果猜测错误，则处理器要丢掉它为该跳转指令后所有指令已经做了的工作，然后再开始从正确位置处起始的指令去填充流水线。这样一个错误的预测会导致大约20~40个时钟周期的浪费。
与条件跳转不同，处理器可以执行条件传送而无需预测测试的结果，处理器只是读源值，检查条件码，然后要么更新目的寄存器，要么保持不变。
使用条件传送也不是总会改进代码的效率，如果条件求值需要大量的计算，那么当相应的条件不满足时，这些工作就白费了。对gcc的实验表明，只有当两个表达式都很容易计算时（即所谓的受限情况）它才会使用条件传送。

### 过程
一个过程调用包括将数据（参数、返回值）和控制从代码的一部分传递到另一部分，在进入过程时为过程的局部变量分配空间，在退出时释放这些空间。大多数机器只提供转移控制到过程和从过程中转移出控制等简单的指令，数据传递、局部变量的分配和释放通过程序栈来操作。

机器用栈来传递参数、存储返回信息、保存寄存器用于以后恢复以及本地存储等。为单个过程分配的那部分栈称为`栈帧`（stack frame）。栈帧以两个指针界定，寄存器%ebp为帧指针，寄存器%esp为栈指针，当程序执行时，栈指针可以移动，因此大多数信息的访问都是相对于帧指针（即帧指针为当前栈帧的固定起点）的。

     [栈底]
+================+
-                -
-      ...       -     [较早的帧]
-                -
+================+
-       ...      -    
-     参数n      -     [调用者的帧]
-     参数1      -
-    返回地址    -
+================+
-      %ebp      -
-       ...      -
-    临时变量    -     [当前帧]
-                -  
+================+  <-- %esp
      [栈顶]

假设过程P调用过程Q，则Q的参数放在P的栈帧中，P中的返回地址被压入栈中，形成P的栈帧的末尾。返回地址就是当程序从Q返回时应该继续执行的地方。过程Q也用栈来保存其他不能存放在寄存器中的局部变量，以及Q调用的其他过程的参数。

栈向低地址方向增长，而栈指针%esp指向栈顶元素，可以用pushl将数据存入栈中并利用popl指令从栈中取出。将栈指针的值减小一定的值可以分配没有指定初始值的数据空间，也可以通过增加栈指针来释放空间。

CPU支持以下过程调用和返回的指令：
  call Label       过程调用
  call *Operand    过程调用
  leave            为返回准备栈
  ret              从过程调用中返回
call指令的效果是将返回地址入栈，并跳转到被调用的过程的起始处。`返回地址是在程序中紧跟在call后面的那条指令的地址`，当被调用的过程返回时，执行会从此处继续。ret指令从栈中弹出地址，并跳转到这个位置。

（数组、组合类型等，略）


## 第4章 处理器体系结构
CPU能够执行的指令被编码为一个或多个字节序列组成的二进制格式，一个CPU能够执行的所有指令和指令的字节级编码被称为它的指令集体系结构（`ISA` Instruction-Set Architecture）。
ISA模型看上去应该是顺序执行指令，但是现代处理器的实际工作方式并非如此：通过同时处理多条指令的不同部分，处理器可以获得较高的性能（流水线化处理器）。为了保证处理器能达到同顺序执行相同的结果，处理器又采取了一些特殊的机制。

### Y86指令集体系结构
每条指令都会读取或修改处理器状态的某些部分。
Y86有8个寄存器%eax、%ecx、%edx、%ebx、%esi、%edi、%esp、%ebp。每个寄存器存储一个字，%esp被入栈、出栈、调用和返回指令作为栈指针，在其他情况下寄存器没有固定的含义或固定值。
有3个1位的条件码：ZF（零）、SF（符号）、OF（溢出），它们保存最近的算术或逻辑指令所造成影响的有关信息。
程序计数器PC存放当前正在执行指令的地址。
存储器从概念上讲是一个很大的字节数组，保存程序和数据，Y86程序用虚拟地址来引用存储器位置，硬件和操作系统一起将虚拟地址翻译成实际物理地址。
状态码Stat表明程序执行的总体状态，如正常运行还是出现了某种异常。

Y86指令集只包括四字节整数操作，寻址方式和操作也比较少，以下是Y86支持的所有指令的表述：
汇编码                字节编码
halt                  0  0
nop                   1  0
rrmovl rA,rB          2  0  rA  rB       r->r  从寄存器移往寄存器
irmovl V,rB           3  0  F   rB  V    i->r  从立即数移往寄存器
rmmovl rA,D(rB)       4  0  rA  rB  D    r->m  从寄存器移往存储器
mrmovl D(rB),rA       5  0  rA  rB  D    m->r  从存储器移往寄存器
注：不允许直接从存储器地址传送到另一个存储器地址，也不允许将立即数传送到存储器。

OPl  rA,rB            6  fn rA  rB  D    
OP代表4种整数操作指令：addl、subl、andl、xorl，这些指令会设置3个条件码ZF、SF、OF

jXX  Dest             7  fn Dest
jXX代表7个跳转指令：jmp、jle、jl、je、jne、jge、jg。

cmovXX rA,rB          2  fn rA  rB
cmovXX代表6个传送指令：cmovle、cmovl、cmove、cmovne、cmovge、cmovg;只有当条件码满足所需要的约束时，才会更新目的寄存器的值。

call Dest             8  0  Dest
将返回地址入栈，然后跳到目的地址，ret指令用于从这样的过程中返回。

ret                   9  0
pushl rA              A  0  rA  F       入栈
popl rA               B  0  rA  F       出栈
其指令编码长度从1个字节到6个字节不等。一条指令含有一个单字节的指令指示符，可能含有一个单字节的寄存器指示符，还可能含有一个4字节的常数字。字段fn指明是某个整数操作OPl、数据移动条件cmovXX或者分支条件jXX。

程序寄存器存在CPU中的一个寄存器文件中，这个寄存器文件就是一个小的、以寄存器ID作为地址的随机访问存储器。

指令集的字节编码必须具有唯一的解释，任意一个字节序列要么是一个唯一的指令序列的编码，要么就不是一个合法的字节序列。（具体指令编码，略）


对于以下函数：
int Sum(int *Start, int Count){
	int sum = 0;
	while(Count){
		sum += *Start;
		Start++;
		Count--;
	}
	return sum;
}
使用Y86得到的汇编代码如下：
Sum:
  pushl %ebp
  rrmovl %esp,%ebp
  mrmovl 8(%ebp),%ecx   ecx = Start
  mrmovl 12(%ebp),%edx  edx = Count
  xorl %eax,%eax        sum = 0
  andl %edx,%edx        Set condition codes
  je End
Loop:
  mrmovl (%ecx),%esi    get *Start
  addl %esi,%eax        add to sum
  irmovl $4,%ebx
  addl %ebx,%ecx        Start++
  irmovl $-1,%ebx
  addl %ebx,%edx        Count--
  jne Loop
End:
   rrmovl %ebp,%esp
   popl %ebp
   ret


### 逻辑设计和硬件控制语言HCL
在硬件设计中用电子电路来计算和存储位，大多数现代电路技术都是用信号线上的高低电压来表示不同的值，如逻辑1用1v左右的高电压表示，而逻辑0用0v左右低电压表示。要实现一个数字系统需要三个主要的组成部分：对位进行操作的组合逻辑、存储位的存储器元素、控制存储器元素更新的时钟信号。

硬件控制语言HCL用来描述不同处理器设计的控制逻辑。HCL表达式可以清楚地表明组合逻辑电路和C语言中逻辑表达式（&&、||、!等）的对应之处。
逻辑门是数字电路的基本计算元素，它们产生的输出等于它们输入位值的某个布尔函数。（图略）
很多逻辑门组合成一个网，就能构建计算块，称为组合电路。
通过将逻辑门组合成更大的网，可以构造出能计算更加复杂逻辑的组合电路，比如设计对字进行操作的电路，而不仅仅是对位进行操作。组合逻辑电路可以设计成在字级数据上执行许多不同类型的操作。算术逻辑单元ALU是一种组合电路，这个电路有3个输入：两个数据输入和一个控制输入，根据控制输入的设置，电路会对数字输入执行不同的算术或逻辑操作。组合电路可以实现将一个信号与多个可能匹配信号的比较，以此来检测正在处理的某个指令代码是否属于某一类指令代码。

组合电路不存储任何信息，为了产生时序电路，即有状态且在这个状态上进行计算的系统，必须引入按位存储信息的设备。存储设备都是由同一个时钟控制，时钟周期性发出信号决定什么时候要把新值加载到设备中。

寄存器文件有两个读端口和一个写端口，这样一个多端口随机访问存储器允许同时进行多个读和写操作，比如可以读两个程序寄存器的值，同时更新第三个寄存器的状态。

### Y86的顺序实现
顺序的处理器即在每个时钟周期上顺序地处理一条完整指令所需的所有步骤。虽然不同指令的动作差异很大，但是所有的指令都遵循统一的执行序列：
取指：从存储器读取指令字节，地址为程序计数器PC的值。取出的长度取决于具体指令的字节编码，然后按顺序方式计算当前指令的下一条指令的地址（等于PC的值加上已取出指令的长度）。
译码：从寄存器文件读入最多两个操作数，通常读入rA和rB字段指明的寄存器，不过有些指令是读寄存器%esp的。
执行：ALU要么执行指令指明的操作（根据ifun值），计算存储器引用的有效地址，要么增加或者减少栈指针。在此，也可能设置条件码。对于跳转指令，这个阶段会验证条件码和（ifun给出的）分支条件，看是不是应该选择分支。
访存：将数据写入存储器或者从存储器中读出。
写回：最多可以写两个结果到寄存器文件。
更新PC：将PC设置为下一条指令的地址。
发生任何异常时，处理器就会停止：执行halt指令或非法指令。

一个时钟变化会引发一个经过组合逻辑的流来执行整个指令。

（硬件实现，略）

顺序处理器的问题在于太慢了，时钟必须非常慢，以使信号能在一个周期内传播所有的阶段（对应不同的硬件单元）。这种实现方式不能充分利用硬件单元。

### 流水线的通用原理
流水线化可以增加系统的吞吐量，即单位时间内服务的总用户数。但是对单个用户而言，则会轻微地增加延迟（从头到尾执行一条指令所需要的时间称为延迟）。
相邻指令之间很可能是相关的，可以通过引入含有反馈路径的流水线系统来解决。（详略）

### Y86的流水线实现
调整顺序处理器中5个阶段的顺序，使得更新PC阶段在一个时钟周期开始时执行，而不是结束时才执行。
（详略）


## 第5章 优化程序性能
编写高性能的程序通常需要以下3类活动：

1.选择合适的算法和数据结构；  
2.编写出编译器能够有效优化以转换成高效可执行代码的源代码；  
3.将任务分成多个部分，并让它们并行地执行； 

本章主要讨论的是其中第2种情况。

### 编译器的能力和局限性
编译器使用复杂的算法来优化程序，大多数编译器都提供了对优化的控制，比如gcc -O1将使用一组基本的优化，而gcc -O3则会进行更全面的优化。更高级别的优化可以进一步提高程序的性能，但是也可能增加程序的规模，并使得程序难以调试。
编译器必须只使用`安全的`的优化，即优化后的程序和未优化的版本应该具有一样的行为。  
```
void func1(int *xp, int *yp){
	*xp += *yp;
	*xp += *yp;
}

void func2(int *xp, int *yp){
	*xp += 2* *yp;
}
```

func1需要6次存储引用（2次读*xp、2次读*yp、2次写*xp），而func2只需要3次存储器引用（读*xp、读*yp、写*xp），因此func2的效率更高，但是当xp等于yp时，fun1将使xp的值变为原来的4倍，而fun2只会将xp增加为原来的3倍，因为编译器只进行安全的优化，如果编译器不能确定两个指针是否指向同一个位置，就必须假设什么情况都有可能，所以不会将func1优化为func2的形式。

再比如：

```
x = 1000;
y = 3000;
*q = y;
*p = x;
v = *q;
```

v的值依赖于指针p和q是否指向存储器中的同一个位置，如果不是，v的值等于3000，如果是，则v的值就是1000。
``

函数调用也可能成为妨碍优化的因素，如：

```
int counter = 0;
int f(){
	return counter ++;
}

int func1(){
	return f() + f() + f() + f();
}

int func2(){
	return 4*f();
}
```

f()函数有一个副作用，即它修改了全局程序状态的一部分，改变它的调用次数会改变程序的行为，因此不能被优化为func2的形式。


### 表示程序性能
使用**CPE** (Cycles Per Element)，来作为度量程序性能的标准。
以计算向量的前置和函数为例，对于长度相同的向量p和a：
p[0] = a[0];
p[i] = p[i-1] + a[i]; 

// 函数psum1每次迭代计算一个元素
void psum1(float a[], float p[], long int n){
	long int i;
	p[0] = a[0];
	for(i=1; i<n; i++){
		p[i] = p[i-1] + a[i]; 
	}
}

// 函数psum2使用循环展开的技术，每次迭代计算两个元素，以此减少迭代的次数
void psum2(float a[], float p[], long int n){
	long int i;
	p[0] = a[0];
	for(i=1; i<n-1; i+=2){
		float mid_val = p[i-1] + a[i];
		p[i] = mid_val; 
		p[i+1] = mid_val + a[i+1];
	}

	if(i<n){
		p[i] = p[i-1] + a[i]; 
	}
}

psum1和psum2的运行时间（以时钟周期为单位）分别近似于496+10.0n和500+6.5n（使用最小二乘法拟合方法得到），对于较大的n值，运行时间就会主要由n来决定，其中n的系数（10.0和6.5）就称为`CPE有效数`。以CPE为度量标准，psum2的CPE为6.5，优于CPE为10.0的psum1。


### 程序示例

\#define IDENT 0
\#define OP +

typedef int data_t;

typedef struct{
	long int len;
	data_t *data;
} vec_rec,*vec_ptr;

vec_ptr new_vec(long int len){
	vec_ptr result = (vec_ptr)malloc(sizeof(vec_rec));
	if(!result){
		return NULL;
	}
	result->len = len;
	if(len>0){
		data_t *data = (data_t *)calloc(len, sizeof(data_t));
		if(!data){
			free((void *) result);
			return NULL;
		}
		result->data = data;
	}
	else{
		result->data = NULL;
	}
	return result;
}

// 将向量中索引为index的元素赋值到dest位置，成功返回1，失败返回0
int get_vec_element(vec_ptr v,long int index,data_t *dest){
	if(index<0 || index>=v->len){
		return 0;
	}
	*dest = v->data[index];
	return 1;
}

long int vec_length(vec_ptr v){
	return v->len;
}

// 向量合并运算的初步实现
void combine1(vec_ptr v,data_t *dest){
	long int i;

	*dest = IDENT;
	for(i = 0; i < vec_length(v); i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
}

combine1函数的CPE如下：
             +         *         +        F*         D*
未优化     20.02     29.21     27.40     27.90     27.36
-O1优化    12.00     12.00     12.00     12.01     13.00

### 消除循环的低效率
void combine2(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v); // 将计算向量长度的运算从循环中移出

	*dest = IDENT;
	for(i = 0; i < length; i++){
		data_t val;
		get_vec_element(v,i,&val);
		*dest = *dest OP val;
	}
}

combine2函数的CPE如下：
             +         *         +        F*         D*
-O1优化    12.00     12.00     12.00     12.01     13.00
combine2    8.03      8.09     10.09     11.09     12.08


### 减少过程调用
过程调用会带来相当大的开销，而且妨碍大多数形式的程序优化。
data_t *get_vec_start(vec_ptr v){
	return v->data;
}

void combine3(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v);
	data_t *data = get_vec_start(v); // 将过程调用从循环中移出

	*dest = IDENT;
	for(i = 0; i < length; i++){
		*dest = *dest OP data[i];
	}
}

             +         *         +        F*         D*
combine2    8.03      8.09     10.09     11.09     12.08
combine3    6.01      8.01     10.01     11.01     12.02

### 消除不必要的存储器引用
combine3中将合并运算计算的值累积在指针dest中，在第i次迭代中，程序读出这个位置处的值，计算后再将其存回到dest，这样的读写很浪费，因为每次迭代开始时从dest中读出的值就是上次迭代最后写入的值。
void combine4(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v);
	data_t *data = get_vec_start(v); 
	data_t acc =IDENT; // 在临时变量中存放结果

	for(i = 0; i < length; i++){
		acc = acc OP data[i];
	}
	*dest = acc;
}
             +         *         +        F*         D*
combine3    6.01      8.01     10.01     11.01     12.02
combine4    2.00      3.00      3.00      4.00      5.00

### 理解现代处理器*
典型的现代处理器可以在每个时钟周期执行多个操作，而且是`乱序`的，可以达到更高的`指令级并行`（基于指令高速缓存、分支预测等实现）。
详略。

### 循环展开
循环展开通过增加每次迭代计算的元素的数量，减少循环的迭代次数。
对于整数加法和乘法，循环展开使CPE有所改进，但是对于浮点数运算却没有，即循环展开不能改进浮点数运算（与CPU进行浮点数计算的方式有关）。
void combine5(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v);
	long int limit = length - 1;
	data_t *data = get_vec_start(v); 
	data_t acc =IDENT;

	// 循环展开2次
	for(i = 0; i < limit; i+=2){
		acc = (acc OP data[i]) OP data[i+1];
	}

	for(; i<length; i++){
		acc = acc OP data[i];
	}

	*dest = acc;
}

             +         *         +        F*         D*
combine4    2.00      3.00      3.00      4.00      5.00
combine5    2.00      1.50      3.00      4.00      5.00


编译器可以很容易地执行循环展开，如gcc可以使用`-funroll-loops`选项来执行循环展开。

### 提高并行性
void combine6(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v);
	long int limit = length - 1;
	data_t *data = get_vec_start(v); 
	data_t acc0 =IDENT;
	data_t acc1 =IDENT;

	// 循环展开2次，并且使用2路并行（因而有两条关键路径）
	for(i = 0; i < limit; i+=2){
		acc0 = acc0 OP data[i];
		acc1 = acc1 OP data[i+1];
	}

	for(; i<length; i++){
		acc0 = acc0 OP data[i];
	}

	*dest = acc0 OP acc1;
}

             +         *         +        F*         D*
combine5    2.00      1.50      3.00      4.00      5.00
combine6    1.50      1.50      1.50      2.00      2.50

编译器能够将combine4中的代码转换为combine5中的二路循环展开变种，再引入并行性，将其转换成combine6的一个变种。

改变内循环中元素合并的方式：
void combine7(vec_ptr v,data_t *dest){
	long int i;
	long int length = vec_length(v);
	long int limit = length - 1;
	data_t *data = get_vec_start(v); 
	data_t acc =IDENT;

	// 循环展开2次
	for(i = 0; i < limit; i+=2){
		acc = acc OP (data[i] OP data[i+1]);  // 重新结合变换
	}

	for(; i<length; i++){
		acc = acc OP data[i];
	}

	*dest = acc;
}

             +         *         +        F*         D*
combine6    1.50      1.50      1.50      2.00      2.50
combine7    2.00      1.51      1.50      2.00      2.97
可以看到该优化对浮点数的计算也是有效的。
重新结合变换能够减少计算中关键路径上的操作的数量，通过更好地利用CPU功能单元的流水线能力得到更好的性能。

如果对循环展开多次，同时使用多路并行，可以使CPE趋近于1：
                     +         *         +        F*         D*
展开5次，5路并行    1.01      1.00      1.00      1.00      1.00

能够利用GCC对SIMD（单指令多数据）向量指令的支持更进一步地提高性能，对于整数和单精度数据，`处理器可以支持每个周期4个合并操作`，而对于双精度数据，每个周期2个。
                +         *         +        F*         D*
SIMD+8次展开   0.25      0.50      0.25      0.25      0.50


### 限制因素
在一个程序的数据流图表示中，关键路径指明了该程序所需时间的一个基本下界，即如果程序中有某条数据相关链，这条链上所有延迟之和等于T，那么这个程序至少需要T个周期才能执行完。

功能单元的吞吐量界限也是程序执行时间的一个下界，即如果一个程序一共需要N个某种运算的计算，而微处理器只有m个能执行这个操作的功能单元，并且这些单元的发射时间为i，那么这个程序的执行时间至少需要N*i/m个周期。

如果并行度超过了可用的寄存器的数量，那么编译器会使用`寄存器溢出`，即把某些临时值存放到栈中，在这种情况下性能会急剧下降。

当分支预测逻辑不能正确预测一个分支是否需要跳转的时候，条件分支可能会导致严重的`预测错误处罚`。处理器的工作超前于正在执行的指令，如果指令遵循的是一种简单的顺序，那么这种指令流水线化就能很好地工作，当遇到分支的时候，处理器必须猜测分支该往哪个方向走。对于`条件转移`的情况，这意味着要预测是否会选择分支，对于`间接跳转`或`过程返回`这样的指令，这意味着预测目标地址。
如果预测是正确的，那么处理器就会提交投机执行的指令的结果，把它们存储到寄存器或存储器中，如果预测结果是错误的，处理器必须丢弃掉所有投机执行的结果，在正确的位置重新开始取指令的过程。对于i7来说，预测错误处罚是44个时钟周期。

最新的x86处理器有条件传送指令，在编译条件语句和表达式时，gcc能够产生使用这些指令的代码，而不是更传统的基于控制的条件转移的实现。翻译成条件传送的基本思想是计算出一个条件表达式或语句两个方向上的值，然后用条件传送选择期望的值。`条件传送指令可以被实现为普通指令流水线化处理的一部分，没有必要猜测条件是否满足，因此猜测错误也没有处罚`。

现代处理器中的分支预测逻辑非常善于辨别不同的分支指令有规律的模式和长期的趋势，因此不要过分关心可预测的分支。对于无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大地提高程序的性能，这不是C语言程序可以直接控制的，但是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。如下两个函数实现同样的功能：将a[i]设置为a[i]和b[i]中较小的那一个，将b[i]设置为较大的那一个。
void minmax1(int a[], int b[], int n){
	int i;
	for(i=0; i<n; i++){
		if(a[i] > b[i]){
			int t =  a[i];
			a[i] = b[i];
			b[i] = t;
		}
	}
}

void minmax2(int a[], int b[], int n){
	int i;
	for(i=0; i<n; i++){
		if(a[i] > b[i]){
			int min = a[i] < b[i] ? a[i] : b[i];
			int max = a[i] < b[i] ? b[i] : a[i];
			a[i] = min;
			b[i] = max;
		}
	}
}

使用随机数据测试minmax1，CPE大约为14.50，使用可预测的数据，CPE大约为3.00~4.00。
对于minmax2，无论哪种类型的数据，CPE大约都为5.0

### 理解存储器性能
现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的存储器操作请求集合，例如i7的`加载单元`的缓冲区可以保存最多48个读请求，而`存储单元`的缓冲区可以保存最多32个写请求。每个这样的单元通常可以每个时钟周期开始一个操作。

合并运算的测试表明，当不使用SIMD时CPE从没有低于1.00，其中一个制约因素是：对于每一个被计算的元素，都需要从存储器中读一个值，由于加载单元每个时钟周期只能启动一条加载操作，所以CPE不可能低于1.00。对于每个被计算的元素必须加载k个值的应用，不可能获得低于k的CPE。

在大多数情况下存储操作与加载操作一样，能够在完全流水线化的模式中工作，每个周期开始一条新的存储。但是与加载操作不同的是，存储操作并不影响任何寄存器值，因此通常一系列存储操作不会产生数据关联，但是当加载操作是受存储操作的结果影响时会有一些问题。如下函数：
void write_read(int *src, int *dest, int n){
	int cnt = n;
	int val = 0;
	while(cnt--){
		*dest = val;
		val = (*src)+1;
	}
}

a的值为[-10,17];
当执行write_read(&a[0],&a[1],3)时，指针引用*src的每次加载都会得到值-10，因此在两次迭代之后，数组的元素就会分别保持固定的-10和-9.从src读出的结果不受对dest写的影响，测试得到这种情况下的CPE为2.00
当执行write_read(&a[0],&a[0],3)时，*src的每次加载都会得到*dest的前次执行存储的值，因而一系列不断增加的值会被存储在这个位置，这就产生了`写读相关`：一个存储器读的结果依赖于一个最近的存储器写，性能测试发现CPE为6.00
写读相关现象产生性能差异的本质在于加载、存储单元的执行方式。存储单元包含一个存储缓冲区，它包含已经被发射到存储单元但还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。提供这样一个缓冲区使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行。当一条加载操作发生时，它必须检查存储缓冲区中的条目，如果有地址相匹配，它就取出相应的数据条目作为加载操作的结果。当存在写读相关时，读操作必须等写操作将其结果放到存储缓冲区中后才能执行，而如果没有写读相关，则两个操作可以独立地进行。
对于寄存器操作，在指令被译码成操作的时候，处理器就可以确定哪些指令会影响其他哪些指令。对于存储器操作，只有计算出加载和存储的地址被计算出来以后，处理器才能确定哪些指令会影响其他的哪些。

### 确认和消除性能瓶颈
（实验，略）

## 第6章 存储器层次结构
如果程序需要的数据是存储在CPU寄存器中的，那么在指令的执行期间，在零个周期内就能访问到它们；如果存储在高速缓存中，需要1~30个周期；如果存储在主存中，需要50~200个周期；如果存储在磁盘上，需要大约几千万个周期。

### 存储技术
随机访问存储器（Random Access Memory）分为两类：静态的和动态的。静态的（SRAM）比动态的（DRAM)更快，也更贵。SRAM用来做高速缓存，DRAM用来做主存及图形系统的帧缓冲区。

SRAM将每个位存储在一个双稳态的存储器单元里，每个单元是一个六晶体管电路，这个电路有这样一个属性：它可以无限期地保持在两个不同的电压状态之一，其他任何状态都是不稳定的。只要有电，它就会永远地保持它的值。

DRAM将每一位存储为一个电容，与SRAM不同的是，DRAM存储器单元对干扰非常敏感，暴露在光线下也会导致电容电压改变，当电容电压被扰乱后，它就永远不会恢复了。存储器系统必须周期性地通过读出，然后重写来刷新存储器的每一位。

SRAM与DRAM的比较：
      每位晶体管数  相对访问时间  是否持续  是否敏感  相对花费
SRAM       6              1          是        否        100    
DRAM       1             10          否        是         1    

SRAM和DRAM在断电后都会丢失信息，因此它们都属于易失的。非易失性存储器即使在断电后也仍然能够保存它们的信息，通常指ROM。由于历史原因，虽然ROM中有的类型既可以读也可以写，但是它们整体上都称为只读存储器ROM。

PROM指可以进行一次编程的ROM，PROM的每个存储器单元有一种熔丝，它只能用高电流熔断一次。

EPROM指可擦写可编程ROM，有一个透明的石英窗口，允许光到达存储单元，紫外线照射后，EPROM单元就被清除为0.对其写入1需要使用特殊的设备来完成。EPROM能够被擦除和重编程的次数大概为1000次。

EEPROM指电子可擦除PROM，类似于EPROM，但是它不需要一个物理上独立的编程设备，且可编程次数超过10万次。

闪存基于EEPROM。

固件（firmware）指存储在ROM中的程序，当计算机通电后，会运行存储在ROM中的固件，如BIOS。复杂的设备，如显卡、磁盘控制器也依赖固件翻译来自CPU的I/O请求。

总线是一种共享电子电路，数据流通过总线在处理器和DRAM之间来回传送。如：

磁盘（略）

固态硬盘（Solid State Disk）是一种基于闪存的存储技术。

### 局部性
一个编写良好的计算机程序应该具有良好的局部性（locality），即它倾向于引用邻近于其最近引用过的数据项或者最近引用过的数据项本身。局部性有两种形式：时间局部性、空间局部性。

### 存储器层次结构
寄存器 -> L1高速缓存 -> L2高速缓存 -> L3高速缓存 -> 主存 -> 本地磁盘 -> 远程存储

### 编写高速缓存友好的代码
局部性比较好的程序更容易有较低的不命中率，因而往往运行的更快。应该试着去编写高速缓存友好的代码。包括以下方法：
1.让最常见的情况运行得快：程序通常把大部分时间花在少量核心的函数上，而这些函数通常把大部分时间花在少量的循环上，因此应该把注意力集中在核心函数的循环上，而忽略其他部分。
2.在每个循环内部缓存不命中数量最小：对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中。步长为1的引用模式是好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块。

### 高速缓存对程序性能的影响
存储器系统的性能不是一个数字就能描述的，它是一座时间和空间局部性的`存储器山`（一个变化很大的程序局部性的函数）。

考虑一对n*n的矩阵相乘问题，矩阵乘法通常由三个嵌套循环实现，分别用索引i、j、k表示，改变循环次序可以得到矩阵乘法的6个在功能上等价的版本。从高层来看，这6个版本的功能是一样的，总共都执行O(n^3)个操作，且加法和乘法的数量相同。但是分析最里层循环迭代的行为可以发现在访问数量和局部性上是有区别的。
假设：
C = AB，AB为n*n的数组。只有一个高速缓存，其块大小为32字节，数组n很大，以至于矩阵的一行都不能完全装进L1高速缓存中。
// ijk版本
for(i=0; i<n; i++){
	for(j=0; j<n; j++){
		sum = 0.0;
		for(k=0; k<n; k++){
			sum += A[i][k] * B[k][j];
		}
		C[i][j] += sum;
	}
}

// jki版本
for(j=0; j<n; j++){
	for(k=0; k<n; k++){
		r = B[k][j];
		for(i=0; i<n; i++){
			C[i][j] += A[i][k]*r;
		}
	}
}

// kij版本
for(k=0; k<n; k++){
	for(i=0; i<n; i++){
		r = A[i][k];
		for(j=0; j<n; j++){
			C[i][j] += B[k][j]*r;
		}
	}
}
其他版本略，性能测试结果如下：
                      ijk&jik   jki&kji   kij&ikj
每次迭代加载次数：       2         2         2
每次迭代存储次数：       0         1         1
每次迭代A不命中次数：   0.25      1.00      0.00
每次迭代B不命中次数：   1.00      0.00      0.25
每次迭代C不命中次数：   0.00      1.00      0.25
每次迭代总不命中次数：  1.25      2.00      0.50
对于大的n值，即使每个版本都执行相同数量的浮点数算术操作，最快的版本（不命中次数最小）比最慢的版本运行得几乎快20倍。

## 第7章 链接





















